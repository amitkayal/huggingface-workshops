{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76571396-8f54-40ed-9e81-6c7531e6eaee",
   "metadata": {},
   "source": [
    "# Compressing SetFit Models with Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b30b35-7875-498f-a771-068132f4084f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup development environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40c7af-1f4f-4324-847c-dc9b7797b60c",
   "metadata": {},
   "source": [
    "Our first step is to install SetFit. Running the following cell will install all the required packages for us including Sentence Transformers and PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a48182-0ad6-4cb0-8974-6cb69dc5e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install setfit neural_compressor optimum[onnxruntime] onnxruntime_extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1832e3f2-09e7-44b5-a438-87ea658d49ea",
   "metadata": {},
   "source": [
    "While we're at it, let's turn off some of the warnings from the ðŸ¤— Datasets library and the tokenizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b67e17b0-743a-47ba-9d55-9baea453a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "datasets.logging.set_verbosity_error()\n",
    "\n",
    "%env TOKENIZERS_PARALLELISM=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442bab8-3ae1-4d1d-9ebe-723d7a829bae",
   "metadata": {},
   "source": [
    "To be able to share your model with the community, there are a few more steps to follow.\n",
    "\n",
    "First, you have to store your authentication token from the Hugging Face Hub (sign up here if you haven't already!). To do so, execute the following cell and input an access token associated with your account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004da15f-6c49-4e7a-b1f6-b285e22eb6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbea843-2e86-4f14-961c-b8895f9de77d",
   "metadata": {},
   "source": [
    "## Create a performance benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "55756fec-fc22-4590-84d7-2f3df37b9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "class PerformanceBenchmark:\n",
    "    def __init__(self, model, dataset, optim_type=\"MPNet (teacher)\"):\n",
    "        self.trainer = SetFitTrainer(\n",
    "            model=model, train_dataset=None, eval_dataset=test_dataset\n",
    "        )\n",
    "        self.optim_type = optim_type\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        accuracy = self.trainer.evaluate()\n",
    "        print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def compute_size(self):\n",
    "        state_dict = self.trainer.model.model_body.state_dict()\n",
    "        tmp_path = Path(\"model.pt\")\n",
    "        torch.save(state_dict, tmp_path)\n",
    "        # Calculate size in megabytes\n",
    "        size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "        # Delete temporary file\n",
    "        tmp_path.unlink()\n",
    "        print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "        return {\"size_mb\": size_mb}\n",
    "\n",
    "    def time_model(self, query=\"What is the pin number for my account?\"):\n",
    "        latencies = []\n",
    "        # Warmup\n",
    "        for _ in range(10):\n",
    "            _ = self.trainer.model([query])\n",
    "        # Timed run\n",
    "        for _ in range(100):\n",
    "            start_time = perf_counter()\n",
    "            _ = self.trainer.model([query])\n",
    "            latency = perf_counter() - start_time\n",
    "            latencies.append(latency)\n",
    "        # Compute run statistics\n",
    "        time_avg_ms = 1000 * np.mean(latencies)\n",
    "        time_std_ms = 1000 * np.std(latencies)\n",
    "        print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "        return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        metrics = {}\n",
    "        metrics[self.optim_type] = self.compute_size()\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        metrics[self.optim_type].update(self.time_model())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1402c1ba-aa7f-4b0b-9db5-1e6f0d301e70",
   "metadata": {},
   "source": [
    "## Train teacher and student baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7850d846-07c8-48eb-9aa6-2ce1af276ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fc95cd24c345da9dfc37176929d347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ag_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "547f9fca-67d9-4b70-86b8-423ce9a60a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import sample_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "b747ce33-22ec-4bff-bc33-dec168df57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"].train_test_split(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "70861fcb-f980-486a-abfb-be97bb6cc446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_teacher = sample_dataset(train_dataset[\"train\"])\n",
    "train_dataset_student = train_dataset[\"test\"].select(range(1000))\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346379a-b64f-497c-93a7-e0e26bcae455",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "52b3bc70-dc3e-4c23-a152-7a149b8b46fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 80\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beed9084ab8a4c3eadf04d6c71178699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ddd59b3fee4d57bf3bb6b0c4d0305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Model size (MB) - 417.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 12.35 +\\- 0.47\n",
      "Accuracy on test set - 0.823\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, SetFitTrainer\n",
    "\n",
    "teacher_model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    ")\n",
    "teacher_trainer = SetFitTrainer(\n",
    "    model=teacher_model, train_dataset=train_dataset_teacher\n",
    ")\n",
    "teacher_trainer.train()\n",
    "pb = PerformanceBenchmark(\n",
    "    model=teacher_trainer.model, dataset=test_dataset, optim_type=\"MPNet (teacher)\"\n",
    ")\n",
    "perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "2cf19a68-cc9f-412b-81dd-e3803c699430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 1280\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 80\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d72023416b47e082e5060ec319624a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed76c3e55544f5787210b14f9671b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 66.36\n",
      "Accuracy on test set - 0.747\n",
      "Average latency (ms) - 4.28 +\\- 0.44\n"
     ]
    }
   ],
   "source": [
    "baseline_model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
    ")\n",
    "baseline_trainer = SetFitTrainer(\n",
    "    model=baseline_model, train_dataset=train_dataset_teacher\n",
    ")\n",
    "baseline_trainer.train()\n",
    "pb = PerformanceBenchmark(baseline_trainer.model, test_dataset, \"MiniLM-L3 (student)\")\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17019479-8651-4d23-9c69-1796073cbd1e",
   "metadata": {},
   "source": [
    "## Train with knowledge distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "893e777c-561c-4184-bb8f-f992fc73a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 40000\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 2500\n",
      "  Total train batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9486886936cb49368046c54d98cc189f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443bc14ea27540ae8c91796ccf4e4637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 66.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 4.26 +\\- 0.15\n",
      "Accuracy on test set - 0.826\n"
     ]
    }
   ],
   "source": [
    "from setfit import DistillationSetFitTrainer\n",
    "\n",
    "student_model = SetFitModel.from_pretrained(\n",
    "    \"sentence-transformers/paraphrase-MiniLM-L3-v2\"\n",
    ")\n",
    "student_trainer = DistillationSetFitTrainer(\n",
    "    teacher_model=teacher_model,\n",
    "    train_dataset=train_dataset_student,\n",
    "    student_model=student_model,\n",
    ")\n",
    "student_trainer.train()\n",
    "pb = PerformanceBenchmark(\n",
    "    student_trainer.student_model, test_dataset, \"MiniLM-L3 (distilled)\"\n",
    ")\n",
    "perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "89d0a144-d463-4a61-b78a-861d0d8cd061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_metrics(perf_metrics, current_optim_type):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        # Add a dashed circle around the current optimization type\n",
    "        if idx == current_optim_type:\n",
    "            plt.scatter(\n",
    "                df_opt[\"time_avg_ms\"],\n",
    "                df_opt[\"accuracy\"] * 100,\n",
    "                alpha=0.5,\n",
    "                s=df_opt[\"size_mb\"],\n",
    "                label=idx,\n",
    "                marker=\"$\\u25CC$\",\n",
    "            )\n",
    "        else:\n",
    "            plt.scatter(\n",
    "                df_opt[\"time_avg_ms\"],\n",
    "                df_opt[\"accuracy\"] * 100,\n",
    "                s=df_opt[\"size_mb\"],\n",
    "                label=idx,\n",
    "                alpha=0.5,\n",
    "            )\n",
    "\n",
    "    legend = plt.legend(bbox_to_anchor=(1, 1))\n",
    "    for handle in legend.legendHandles:\n",
    "        handle.set_sizes([20])\n",
    "\n",
    "    plt.ylim(63, 95)\n",
    "    # Use the slowest model to define the x-axis range\n",
    "    xlim = int(perf_metrics[\"MPNet (teacher)\"][\"time_avg_ms\"] + 3)\n",
    "    plt.xlim(1, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency (ms)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_metrics(perf_metrics, \"MiniLM-L3 (distilled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64707fb5-b4eb-4999-966a-1455d3137a79",
   "metadata": {},
   "source": [
    "## Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "021c5d10-ada6-4963-8337-96530f1c5414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'push_to_hub': pass repo_path_or_name='setfit-minilm-distilled', repo_url=None, commit_message='Add SetFit model', organization=None, private=None, api_endpoint=None, use_auth_token=None, git_user=None, git_email=None, config=None, skip_lfs_files=False as keyword args. From version 0.12 passing these as positional arguments will result in an error,\n",
      "  warnings.warn(\n",
      "/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'push_to_hub': repo_path_or_name. Will not be supported from version '0.12'.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Cloning https://huggingface.co/lewtun/setfit-minilm-distilled into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a4c2f6bb5a48c4ae0483850e89651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/66.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753e825341f2400fbf9b1de458354ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file model_head.pkl: 100%|##########| 12.9k/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/lewtun/setfit-minilm-distilled\n",
      "   2d4b309..9c0a08a  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/lewtun/setfit-minilm-distilled/commit/9c0a08a87a55fe4e0b30c490fff0398dcde86998'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_trainer.push_to_hub(\"setfit-minilm-distilled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b4436-6f5a-4d55-b511-6a986b15a290",
   "metadata": {},
   "source": [
    "## Create ONNX wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "0cbcde90-2fc8-439a-aa85-b6b247036f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('onnx/tokenizer_config.json',\n",
       " 'onnx/special_tokens_map.json',\n",
       " 'onnx/vocab.txt',\n",
       " 'onnx/added_tokens.json',\n",
       " 'onnx/tokenizer.json')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "from transformers import AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "model_id = \"setfit-minilm-distilled/\"\n",
    "onnx_path = Path(\"onnx\")\n",
    "\n",
    "# load vanilla transformers and convert to onnx\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0966dc92-7198-4809-96d7-97732f127407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Pipeline\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# copied from the model card\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "class SentenceEmbeddingPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        # we don't have any hyperameters to sanitize\n",
    "        preprocess_kwargs = {}\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        encoded_inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')\n",
    "        return encoded_inputs\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        outputs = self.model(**model_inputs)\n",
    "        return {\"outputs\": outputs, \"attention_mask\": model_inputs[\"attention_mask\"]}\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(model_outputs[\"outputs\"], model_outputs['attention_mask'])\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "270d30b3-66a9-4eb8-9aa3-a740c3e0a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_pipeline = SentenceEmbeddingPipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b658a8c2-0a41-4688-8cdd-f539f6de4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.pipelines import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ae340289-cbf0-46ad-b181-ca80c8dacad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_model = ORTModelForFeatureExtraction.from_pretrained(\"onnx\")\n",
    "p = pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7a6a891f-47a8-4a80-9179-8a1d2412be97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 384])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(\"hi\", return_tensors=\"pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f5fd2005-8ce4-432a-9b80-ef2f002bb062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import onnxruntime\n",
    "\n",
    "import evaluate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from optimum.pipelines import ORTModelForFeatureExtraction\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def eval_func(model):\n",
    "    ort_model = ORTModelForFeatureExtraction.from_pretrained(\"onnx\")\n",
    "    ort_model.model = onnxruntime.InferenceSession(model.SerializeToString(), None)\n",
    "    onnx_pipeline = SentenceEmbeddingPipeline(ort_model, tokenizer)\n",
    "    \n",
    "    def get_data(onnx_pipeline, dataset):\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        for model_input in tqdm(dataset):\n",
    "            labels.append([model_input[\"label\"]])\n",
    "            embedding = onnx_pipeline(model_input[\"text\"])\n",
    "            embedding = embedding.detach().cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "        return np.concatenate(embeddings, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "    # train logistic regressor\n",
    "    embeddings, labels = get_data(onnx_pipeline, train_dataset_teacher)\n",
    "    sgd = LogisticRegression(max_iter=200)\n",
    "    sgd.fit(embeddings, labels)\n",
    "\n",
    "    # evaluate\n",
    "    embeddings, labels = get_data(onnx_pipeline, test_dataset)\n",
    "    y_pred_test_sgd = sgd.predict(embeddings)\n",
    "    scores = accuracy.compute(predictions=y_pred_test_sgd, references=labels)\n",
    "    return scores[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "bbf50aca-1a3b-4bbf-87f2-b7271f714dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_quant_yaml():\n",
    "    yaml = \"\"\"\n",
    "model:\n",
    "  name: bert\n",
    "  framework: onnxrt_integerops\n",
    "  \n",
    "device: cpu\n",
    "\n",
    "quantization:\n",
    "  approach: post_training_dynamic_quant\n",
    "\n",
    "tuning:\n",
    "  accuracy_criterion:\n",
    "    relative: 0.01\n",
    "  exit_policy:\n",
    "    timeout: 0\n",
    "  random_seed: 9527\n",
    "    \"\"\"\n",
    "    with open(\"MiniLM_L3_ST_distilled_onnx_dynamic.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(yaml)\n",
    "\n",
    "\n",
    "build_dynamic_quant_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d831000c-f43f-4700-a619-9030f52717b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_compressor.experimental import Quantization, common\n",
    "\n",
    "onnx_int8_inc_dynamic_model_path = \"onnx/MiniLM_L3_int8_dynamic.onnx\"\n",
    "quantizer = Quantization(\"MiniLM_L3_ST_distilled_onnx_dynamic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6478608c-716a-4cbf-b2b1-7ff7b1c8e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer.model = common.Model(\"onnx/model.onnx\")\n",
    "quantizer.eval_func = functools.partial(eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "14b9e984-cd83-4a45-8ec6-968e08350bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:57:18 [INFO] Get FP32 model baseline.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e732cddd6b5e485da7349ef12232ba05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ea1ca8114748eeaab5f1ef501f83da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 15:57:22 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n"
     ]
    }
   ],
   "source": [
    "q_model = quantizer()\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "cdd70f51-ae4a-4947-a911-1dfc746617af",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_model.save(\"onnx/model_quantized.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d99d3067-46db-4899-b88b-375b6db09a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = ORTModelForFeatureExtraction.from_pretrained(\"onnx\", from_file=\"model_quantized.onnx\")\n",
    "p = pipeline(\"feature-extraction\", model=mm, tokenizer=tokenizer)\n",
    "# p(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "306f5a0b-2c9c-47d3-805e-13b8a09e94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"onnx/model_quantized.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ebf07691-4dc2-44c2-963a-020556dae27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcbf03a78f349488b979f322d94ab8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a82b3f5e2af489b8288b807d0dec407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.824078947368421"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_func(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "9ee5a7ad-22cb-4193-a7bc-d01ef47b5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_model(query=\"What is the pin number for my account?\"):\n",
    "    latencies = []\n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        _ = p([query])\n",
    "    # Timed run\n",
    "    for _ in range(100):\n",
    "        start_time = perf_counter()\n",
    "        _ = p([query])\n",
    "        latency = perf_counter() - start_time\n",
    "        latencies.append(latency)\n",
    "    # Compute run statistics\n",
    "    time_avg_ms = 1000 * np.mean(latencies)\n",
    "    time_std_ms = 1000 * np.std(latencies)\n",
    "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "5be9567f-66e1-4201-b3cf-75acf696ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency (ms) - 2.12 +\\- 0.09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'time_avg_ms': 2.12231026016525, 'time_std_ms': 0.09418140866212008}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044ed30-cd16-4da0-a2cf-4f2070085a42",
   "metadata": {},
   "source": [
    "## Create torch wrapper?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "562881b8-38cb-4e34-b538-ff62b266d19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        \"last_hidden_state\"\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "class SetFitWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        if hasattr(model, \"config\"):\n",
    "            self.config = model.config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, *args, **kwargs):\n",
    "        if token_type_ids is not None:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "        else:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "        return mean_pooling(model_output, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e0fb3c-9c10-4ec7-ba5a-67a9d1e2910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"setfit-mnpet-distilled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6c882d7e-e6c4-4187-89ea-c6d9384010b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e615ccb990e746bba289f5614e407422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset_teacher_encoded = train_dataset_teacher.map(\n",
    "    lambda x: tokenizer(x[\"text\"], padding=True, truncation=True), remove_columns=[\"text\"], batched=True\n",
    ")\n",
    "train_dataset_teacher_encoded.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "14754fe1-18b1-4137-9262-4533175446ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5daec51a96e54e6e84b07ceca594e0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset_encoded = test_dataset.map(\n",
    "    lambda x: tokenizer(x[\"text\"], padding=True, truncation=True), remove_columns=[\"text\"], batched=True\n",
    ")\n",
    "test_dataset_encoded.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fe765578-7244-490d-aed1-93ac645d598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 32\n",
       "})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_teacher_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bc0edcbf-b664-4f9d-b1c8-fa777ab3ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7da77282-10f7-4ba6-9f42-8d7f89654b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset_teacher_encoded)\n",
    "test_dataloader = DataLoader(test_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3f5cd416-1c72-4747-8534-6b3c8fe78e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import evaluate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def eval_func(model):\n",
    "    setfit_model = SetFitWrapper(model)\n",
    "\n",
    "    def get_data(model, dataloader):\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        for idx, model_input in tqdm(enumerate(dataloader)):\n",
    "            labels.append(model_input.pop(\"label\").numpy())\n",
    "            embedding = model(**model_input)\n",
    "            embedding = embedding.detach().cpu().numpy()\n",
    "            embeddings.append(embedding)\n",
    "        return np.concatenate(embeddings, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "    # train logistic regressor\n",
    "    embeddings, labels = get_data(setfit_model, train_dataloader)\n",
    "    sgd = LogisticRegression(max_iter=200)\n",
    "    sgd.fit(embeddings, labels)\n",
    "\n",
    "    # evaluate\n",
    "    embeddings, labels = get_data(setfit_model, test_dataloader)\n",
    "    y_pred_test_sgd = sgd.predict(embeddings)\n",
    "    scores = accuracy.compute(predictions=y_pred_test_sgd, references=labels)\n",
    "    return scores[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51a5dd-25f2-4149-8b68-7859e0bb014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_body = AutoModel.from_pretrained(\"setfit-mnpet-distilled\")\n",
    "eval_func(model_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f2d02cba-61aa-4aed-8231-7cabbca68426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dynamic_quant_yaml():\n",
    "    yaml = \"\"\"\n",
    "model:\n",
    "  name: bert\n",
    "  framework: pytorch\n",
    "  \n",
    "device: cpu\n",
    "\n",
    "quantization:\n",
    "  approach: post_training_dynamic_quant\n",
    "\n",
    "tuning:\n",
    "  accuracy_criterion:\n",
    "    relative: 0.01\n",
    "  exit_policy:\n",
    "    timeout: 0\n",
    "  random_seed: 9527\n",
    "    \"\"\"\n",
    "    with open(\"MiniLM_L3_ST_distilled_onnx_dynamic.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(yaml)\n",
    "\n",
    "\n",
    "build_dynamic_quant_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "469250d3-6f6a-4b39-a6cf-8fdee6272001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_compressor.experimental import Quantization, common\n",
    "\n",
    "onnx_int8_inc_dynamic_model_path = \"onnx/MiniLM_L3_int8_dynamic.onnx\"\n",
    "quantizer = Quantization(\"MiniLM_L3_ST_distilled_onnx_dynamic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f13ff6dc-3999-4479-a2ba-caad8129b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_body = AutoModel.from_pretrained(\"setfit-mnpet-distilled\")\n",
    "wrapper = SetFitWrapper(model_body)\n",
    "quantizer.model = common.Model(model_body)\n",
    "quantizer.eval_func = functools.partial(eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "de1e4ceb-b045-4b7b-829e-f1dae1c4ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:33:02 [INFO] Pass query framework capability elapsed time: 2.51 ms\n",
      "2022-12-13 14:33:02 [INFO] Get FP32 model baseline.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "befe87ee5e2b4a72a80a10a862e27ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f0501d46a346ee9f1d8d679fe5c4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:34:55 [INFO] Save tuning history to /home/lewis_huggingface_co/git/workshops/fewshot-learning-in-production/nc_workspace/2022-12-13_13-41-29/./history.snapshot.\n",
      "2022-12-13 14:34:55 [INFO] FP32 baseline is: [Accuracy: 0.8178, Duration (seconds): 113.0321]\n",
      "/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/torch/ao/quantization/qconfig.py:92: UserWarning: QConfigDynamic is going to be deprecated in PyTorch 1.12, please use QConfig instead\n",
      "  warnings.warn(\"QConfigDynamic is going to be deprecated in PyTorch 1.12, please use QConfig instead\")\n",
      "2022-12-13 14:34:56 [INFO] |******Mixed Precision Statistics*****|\n",
      "2022-12-13 14:34:56 [INFO] +----------------+----------+---------+\n",
      "2022-12-13 14:34:56 [INFO] |    Op Type     |  Total   |   INT8  |\n",
      "2022-12-13 14:34:56 [INFO] +----------------+----------+---------+\n",
      "2022-12-13 14:34:56 [INFO] |   Embedding    |    3     |    3    |\n",
      "2022-12-13 14:34:56 [INFO] |     Linear     |    19    |    19   |\n",
      "2022-12-13 14:34:56 [INFO] +----------------+----------+---------+\n",
      "2022-12-13 14:34:56 [INFO] Pass quantize model elapsed time: 213.89 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eecdbb2c8940d28be6adc9cdc8a470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5031976b844f3d989727de20acc748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 14:36:50 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.8203|0.8178, Duration (seconds) (int8|fp32): 114.7929|113.0321], Best tune result is: [Accuracy: 0.8203, Duration (seconds): 114.7929]\n",
      "2022-12-13 14:36:50 [INFO] |***********************Tune Result Statistics**********************|\n",
      "2022-12-13 14:36:50 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2022-12-13 14:36:50 [INFO] |     Info Type      |  Baseline | Tune 1 result | Best tune result |\n",
      "2022-12-13 14:36:50 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2022-12-13 14:36:50 [INFO] |      Accuracy      |  0.8178   |    0.8203     |     0.8203       |\n",
      "2022-12-13 14:36:50 [INFO] | Duration (seconds) | 113.0321  |   114.7929    |    114.7929      |\n",
      "2022-12-13 14:36:50 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2022-12-13 14:36:50 [INFO] Save tuning history to /home/lewis_huggingface_co/git/workshops/fewshot-learning-in-production/nc_workspace/2022-12-13_13-41-29/./history.snapshot.\n",
      "2022-12-13 14:36:50 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2022-12-13 14:36:50 [INFO] Save deploy yaml to /home/lewis_huggingface_co/git/workshops/fewshot-learning-in-production/nc_workspace/2022-12-13_13-41-29/deploy.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyTorchModel(\n",
       "  (_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): QuantizedEmbedding(num_embeddings=30522, embedding_dim=384, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
       "      (position_embeddings): QuantizedEmbedding(num_embeddings=512, embedding_dim=384, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
       "      (token_type_embeddings): QuantizedEmbedding(num_embeddings=2, embedding_dim=384, dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (key): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (value): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): DynamicQuantizedLinear(in_features=384, out_features=1536, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): DynamicQuantizedLinear(in_features=1536, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (key): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (value): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): DynamicQuantizedLinear(in_features=384, out_features=1536, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): DynamicQuantizedLinear(in_features=1536, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (key): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (value): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): DynamicQuantizedLinear(in_features=384, out_features=1536, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): DynamicQuantizedLinear(in_features=1536, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): DynamicQuantizedLinear(in_features=384, out_features=384, dtype=torch.qint8, qscheme=torch.per_channel_affine)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model = quantizer()\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a2e0bbcd-7f41-4898-ae22-37db86e0cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at setfit-mnpet-distilled-quantized/ were not used when initializing BertModel: ['encoder.layer.0.attention.self.value._packed_params.dtype', 'encoder.layer.2.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.key._packed_params._packed_params', 'encoder.layer.1.attention.output.dense._packed_params.dtype', 'encoder.layer.0.intermediate.dense.zero_point', 'encoder.layer.1.output.dense.scale', 'encoder.layer.1.attention.self.query._packed_params.dtype', 'encoder.layer.1.intermediate.dense.scale', 'encoder.layer.1.attention.output.dense.scale', 'encoder.layer.1.attention.self.value._packed_params._packed_params', 'encoder.layer.0.attention.self.value._packed_params._packed_params', 'encoder.layer.2.attention.self.query._packed_params.dtype', 'encoder.layer.1.attention.self.value.zero_point', 'encoder.layer.0.output.dense._packed_params.dtype', 'encoder.layer.1.attention.self.query._packed_params._packed_params', 'encoder.layer.1.attention.self.value._packed_params.dtype', 'encoder.layer.2.attention.output.dense._packed_params._packed_params', 'encoder.layer.1.output.dense._packed_params.dtype', 'encoder.layer.0.attention.output.dense._packed_params._packed_params', 'encoder.layer.0.intermediate.dense._packed_params.dtype', 'encoder.layer.2.attention.self.key._packed_params._packed_params', 'encoder.layer.0.output.dense.scale', 'encoder.layer.1.intermediate.dense.zero_point', 'encoder.layer.1.attention.self.key.scale', 'embeddings.position_embeddings._packed_params.dtype', 'pooler.dense._packed_params.dtype', 'encoder.layer.2.intermediate.dense.scale', 'encoder.layer.2.attention.self.key._packed_params.dtype', 'encoder.layer.0.attention.self.key.scale', 'encoder.layer.1.attention.self.value.scale', 'encoder.layer.0.attention.self.value.scale', 'encoder.layer.0.intermediate.dense.scale', 'encoder.layer.0.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.query._packed_params._packed_params', 'encoder.layer.2.attention.output.dense.scale', 'encoder.layer.2.output.dense.scale', 'encoder.layer.2.attention.self.key.scale', 'encoder.layer.0.attention.output.dense.scale', 'pooler.dense._packed_params._packed_params', 'encoder.layer.0.output.dense._packed_params._packed_params', 'encoder.layer.0.attention.output.dense._packed_params.dtype', 'encoder.layer.1.output.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.value._packed_params.dtype', 'encoder.layer.0.attention.self.query.scale', 'encoder.layer.0.intermediate.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.value._packed_params._packed_params', 'encoder.layer.2.intermediate.dense.zero_point', 'embeddings.token_type_embeddings._packed_params.dtype', 'embeddings.position_embeddings._packed_params._packed_weight', 'pooler.dense.scale', 'encoder.layer.2.attention.self.value.scale', 'encoder.layer.2.output.dense._packed_params.dtype', 'encoder.layer.1.output.dense.zero_point', 'encoder.layer.1.attention.self.key._packed_params._packed_params', 'encoder.layer.2.attention.self.query.scale', 'encoder.layer.1.attention.output.dense._packed_params._packed_params', 'encoder.layer.0.attention.self.key._packed_params.dtype', 'encoder.layer.1.attention.self.key._packed_params.dtype', 'encoder.layer.2.intermediate.dense._packed_params.dtype', 'embeddings.word_embeddings._packed_params._packed_weight', 'encoder.layer.2.output.dense.zero_point', 'encoder.layer.0.attention.self.query._packed_params.dtype', 'encoder.layer.1.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.query.zero_point', 'best_configure', 'encoder.layer.2.attention.self.value.zero_point', 'encoder.layer.0.attention.self.value.zero_point', 'encoder.layer.1.attention.self.key.zero_point', 'pooler.dense.zero_point', 'encoder.layer.2.intermediate.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.query.zero_point', 'encoder.layer.1.attention.self.query.zero_point', 'encoder.layer.2.attention.output.dense._packed_params.dtype', 'embeddings.word_embeddings._packed_params.dtype', 'encoder.layer.1.intermediate.dense._packed_params._packed_params', 'embeddings.token_type_embeddings._packed_params._packed_weight', 'encoder.layer.2.output.dense._packed_params._packed_params', 'encoder.layer.1.attention.self.query.scale', 'encoder.layer.0.attention.self.key.zero_point', 'encoder.layer.0.output.dense.zero_point', 'encoder.layer.2.attention.self.query._packed_params._packed_params', 'encoder.layer.2.attention.self.key.zero_point', 'encoder.layer.1.intermediate.dense._packed_params.dtype']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at setfit-mnpet-distilled-quantized/ and are newly initialized: ['encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.2.0 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model = SetFitModel.from_pretrained(\"setfit-mnpet-distilled-quantized/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "920bd7e3-685d-495b-8301-f3901fb2ce9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 66.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'size_mb': 66.36254596710205}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PerformanceBenchmark(\n",
    "    best_model, test_dataset, \"MiniLM-L3 (distilled + quantized)\"\n",
    ")\n",
    "pb.compute_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "962d1ea7-56a6-47e9-8d55-387ef94022ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at setfit-mnpet-distilled-quantized were not used when initializing BertModel: ['encoder.layer.0.attention.self.value._packed_params.dtype', 'encoder.layer.2.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.key._packed_params._packed_params', 'encoder.layer.1.attention.output.dense._packed_params.dtype', 'encoder.layer.0.intermediate.dense.zero_point', 'encoder.layer.1.output.dense.scale', 'encoder.layer.1.attention.self.query._packed_params.dtype', 'encoder.layer.1.intermediate.dense.scale', 'encoder.layer.1.attention.output.dense.scale', 'encoder.layer.1.attention.self.value._packed_params._packed_params', 'encoder.layer.0.attention.self.value._packed_params._packed_params', 'encoder.layer.2.attention.self.query._packed_params.dtype', 'encoder.layer.1.attention.self.value.zero_point', 'encoder.layer.0.output.dense._packed_params.dtype', 'encoder.layer.1.attention.self.query._packed_params._packed_params', 'encoder.layer.1.attention.self.value._packed_params.dtype', 'encoder.layer.2.attention.output.dense._packed_params._packed_params', 'encoder.layer.1.output.dense._packed_params.dtype', 'encoder.layer.0.attention.output.dense._packed_params._packed_params', 'encoder.layer.0.intermediate.dense._packed_params.dtype', 'encoder.layer.2.attention.self.key._packed_params._packed_params', 'encoder.layer.0.output.dense.scale', 'encoder.layer.1.intermediate.dense.zero_point', 'encoder.layer.1.attention.self.key.scale', 'embeddings.position_embeddings._packed_params.dtype', 'pooler.dense._packed_params.dtype', 'encoder.layer.2.intermediate.dense.scale', 'encoder.layer.2.attention.self.key._packed_params.dtype', 'encoder.layer.0.attention.self.key.scale', 'encoder.layer.1.attention.self.value.scale', 'encoder.layer.0.attention.self.value.scale', 'encoder.layer.0.intermediate.dense.scale', 'encoder.layer.0.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.query._packed_params._packed_params', 'encoder.layer.2.attention.output.dense.scale', 'encoder.layer.2.output.dense.scale', 'encoder.layer.2.attention.self.key.scale', 'encoder.layer.0.attention.output.dense.scale', 'pooler.dense._packed_params._packed_params', 'encoder.layer.0.output.dense._packed_params._packed_params', 'encoder.layer.0.attention.output.dense._packed_params.dtype', 'encoder.layer.1.output.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.value._packed_params.dtype', 'encoder.layer.0.attention.self.query.scale', 'encoder.layer.0.intermediate.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.value._packed_params._packed_params', 'encoder.layer.2.intermediate.dense.zero_point', 'embeddings.token_type_embeddings._packed_params.dtype', 'embeddings.position_embeddings._packed_params._packed_weight', 'pooler.dense.scale', 'encoder.layer.2.attention.self.value.scale', 'encoder.layer.2.output.dense._packed_params.dtype', 'encoder.layer.1.output.dense.zero_point', 'encoder.layer.1.attention.self.key._packed_params._packed_params', 'encoder.layer.2.attention.self.query.scale', 'encoder.layer.1.attention.output.dense._packed_params._packed_params', 'encoder.layer.0.attention.self.key._packed_params.dtype', 'encoder.layer.1.attention.self.key._packed_params.dtype', 'encoder.layer.2.intermediate.dense._packed_params.dtype', 'embeddings.word_embeddings._packed_params._packed_weight', 'encoder.layer.2.output.dense.zero_point', 'encoder.layer.0.attention.self.query._packed_params.dtype', 'encoder.layer.1.attention.output.dense.zero_point', 'encoder.layer.0.attention.self.query.zero_point', 'best_configure', 'encoder.layer.2.attention.self.value.zero_point', 'encoder.layer.0.attention.self.value.zero_point', 'encoder.layer.1.attention.self.key.zero_point', 'pooler.dense.zero_point', 'encoder.layer.2.intermediate.dense._packed_params._packed_params', 'encoder.layer.2.attention.self.query.zero_point', 'encoder.layer.1.attention.self.query.zero_point', 'encoder.layer.2.attention.output.dense._packed_params.dtype', 'embeddings.word_embeddings._packed_params.dtype', 'encoder.layer.1.intermediate.dense._packed_params._packed_params', 'embeddings.token_type_embeddings._packed_params._packed_weight', 'encoder.layer.2.output.dense._packed_params._packed_params', 'encoder.layer.1.attention.self.query.scale', 'encoder.layer.0.attention.self.key.zero_point', 'encoder.layer.0.output.dense.zero_point', 'encoder.layer.2.attention.self.query._packed_params._packed_params', 'encoder.layer.2.attention.self.key.zero_point', 'encoder.layer.1.intermediate.dense._packed_params.dtype']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at setfit-mnpet-distilled-quantized and are newly initialized: ['encoder.layer.2.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.weight', 'pooler.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'pooler.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85331f4e2ca4dc89686b637de58f36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2ec874ae9943d9b78ddde7d509ba08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.3430263157894737"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_body = AutoModel.from_pretrained(\"setfit-mnpet-distilled-quantized\")\n",
    "eval_func(model_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b7a05a-4b8c-49ca-afcd-c7fc377f0f1f",
   "metadata": {},
   "source": [
    "## DOWN TO HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff9861-f922-43a4-8df2-ab74b7e91720",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57b94e3-ff95-459b-8567-6119fb4ab6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::Constant type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    }
   ],
   "source": [
    "from setfit.exporters.onnx import export_onnx\n",
    "\n",
    "output_path = \"setfit_model.onnx\"\n",
    "export_onnx(\n",
    "    student_trainer.student_model.model_body.to(\"cpu\"),\n",
    "    student_trainer.student_model.model_head,\n",
    "    opset=12,\n",
    "    output_path=output_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2043433a-76ec-43ad-a931-f175e6cfb523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Oracle sees profits surge 16 Oracle, the world #39;s second largest software producer, has seen first quarter profits surge 16 on the back of strong sales of database products.',\n",
       "  'Social Security a Priority for White House (AP) AP - THE PROBLEM: Social Security faces a  #36;3.7 trillion shortfall over 75 years.'],\n",
       " 'label': [2, 0]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b211ef29-c38f-4137-867b-fe2d37d5e1dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0de71e08606489ebf478a5e90ade05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model(train_dataset[\"train\"].shuffle(seed=0)[:2][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb8f1b93-31b1-409a-a764-5e3b15a8d605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9069cb018af843969683c486886caf93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model(train_dataset[\"train\"].shuffle(seed=0)[:2][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877c278-06da-438b-af81-8e7c1a7b338a",
   "metadata": {},
   "source": [
    "### Quantize with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d353a688-e02a-42c0-9824-27c74e4699b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"setfit-mnpet-distilled\")\n",
    "input_text = train_dataset[\"train\"].shuffle(seed=0)[:2][\"text\"]\n",
    "\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_token_type_ids=True,\n",
    "    return_tensors=\"np\",\n",
    ")\n",
    "\n",
    "session = onnxruntime.InferenceSession(output_path)\n",
    "\n",
    "onnx_preds = session.run(None, dict(inputs))[0]\n",
    "onnx_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5677b27-eb47-457c-9a64-c71f48dc2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e192b2b5-7e96-41df-ab48-7fee66feb52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model.SerializeToString(), None)\n",
    "onnx_preds = session.run(None, dict(inputs))[0]\n",
    "onnx_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a7d2d-8bc7-428c-9ebc-7e6d13a4b1f9",
   "metadata": {},
   "source": [
    "## Quantize with Intel Neural Compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a12d5494-9ced-4baf-9988-228aab315453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('onnx/tokenizer_config.json',\n",
       " 'onnx/special_tokens_map.json',\n",
       " 'onnx/vocab.txt',\n",
       " 'onnx/added_tokens.json',\n",
       " 'onnx/tokenizer.json')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "onnx_path = Path(\"onnx\")\n",
    "\n",
    "# load vanilla transformers and convert to onnx\n",
    "model_id = \"setfit-mnpet-distilled\"\n",
    "model = ORTModelForFeatureExtraction.from_pretrained(model_id, from_transformers=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# save onnx checkpoint and tokenizer\n",
    "model.save_pretrained(onnx_path)\n",
    "tokenizer.save_pretrained(onnx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "925238fb-343d-4477-8b85-dc83a3baeb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from setfit.exporters.utils import mean_pooling\n",
    "from transformers import Pipeline\n",
    "\n",
    "\n",
    "class OnnxPipeline(Pipeline):\n",
    "    def _sanitize_parameters(self, **kwargs):\n",
    "        # we don't have any hyperameters to sanitize\n",
    "        preprocess_kwargs = {}\n",
    "        return preprocess_kwargs, {}, {}\n",
    "\n",
    "    def preprocess(self, inputs):\n",
    "        encoded_inputs = self.tokenizer(\n",
    "            inputs, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        return encoded_inputs\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        outputs = self.model(**model_inputs)\n",
    "        return {\"outputs\": outputs, \"attention_mask\": model_inputs[\"attention_mask\"]}\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(\n",
    "            model_outputs[\"outputs\"], model_outputs[\"attention_mask\"]\n",
    "        )\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings\n",
    "\n",
    "    def encode(self, model_outputs):\n",
    "        # Perform pooling\n",
    "        sentence_embeddings = mean_pooling(\n",
    "            model_outputs[\"outputs\"], model_outputs[\"attention_mask\"]\n",
    "        )\n",
    "        # Normalize embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4ee2313-7419-4522-ba4b-5f0e626d650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        \"last_hidden_state\"\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9, max=1e9\n",
    "    )\n",
    "\n",
    "\n",
    "class TorchModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        if hasattr(model, \"config\"):\n",
    "            self.config = model.config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, *args, **kwargs):\n",
    "        if token_type_ids is not None:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "        else:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask)\n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f225f0-b2ce-4c44-b79e-2f887613183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"tmp\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ab0adb5-ee3d-435c-9134-e63c0ed7ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import evaluate\n",
    "import onnxruntime\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def eval_func(model):\n",
    "    setfit_model = TorchModel(model)\n",
    "\n",
    "    def get_data(model, dataset):\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        for model_input in tqdm(dataset):\n",
    "            labels.append(model_input[\"label\"])\n",
    "            embedding = model(**model_input)\n",
    "            embedding = embedding.detach().cpu().numpy()\n",
    "        return np.concatenate(embeddings, axis=0), np.concatenate(labels, axis=0)\n",
    "\n",
    "    # train logistic regressor\n",
    "    embeddings, labels = get_data(setfit_model, train_dataset_teacher)\n",
    "    sgd = LogisticRegression(max_iter=200)\n",
    "    sgd.fit(embeddings, labels)\n",
    "\n",
    "    # evaluate\n",
    "    embeddings, labels = get_data(setfit_model, test_dataset)\n",
    "    y_pred_test_sgd = sgd.predict(embeddings)\n",
    "\n",
    "    return accuracy.compute(y_pred_test_sgd, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2a1971a-858f-4cf8-a3a1-f16fda53c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def eval_func(model):\n",
    "    setfit_model = onnxruntime.InferenceSession(onnx_model.SerializeToString(), None)\n",
    "    input_text = test_dataset[\"text\"][:]\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    preds = session.run(None, dict(inputs))[0]\n",
    "    score = accuracy.compute(preds, test_dataset[\"label\"][:])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4a3ef563-11b9-411b-83e1-24907ab9540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_func(model):\n",
    "    trainer = SetFitTrainer(\n",
    "        model=model, train_dataset=train_dataset_teacher, eval_dataset=test_dataset\n",
    "    )\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    return metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a6b72060-ca80-49da-8053-48ea28e1ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        \"last_hidden_state\"\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9, max=1e9\n",
    "    )\n",
    "\n",
    "\n",
    "class TorchModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        if hasattr(model, \"config\"):\n",
    "            self.config = model.config\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None, *args, **kwargs):\n",
    "        if token_type_ids is not None:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids,\n",
    "                token_type_ids=token_type_ids,\n",
    "                attention_mask=attention_mask,\n",
    "            )\n",
    "        else:\n",
    "            model_output = self.model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            )\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask)\n",
    "        return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6275870a-8439-4b5b-b250-dfb27b790eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_compressor.experimental import Quantization, common\n",
    "\n",
    "onnx_int8_inc_dynamic_model_path = \"onnx/MiniLM_L3_int8_dynamic.onnx\"\n",
    "model_input = \"setfit_model.onnx\"\n",
    "quantizer = Quantization(\"MiniLM_L3_ST_distilled_onnx_dynamic.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7b8fab8-2168-46ab-8c8a-e4a35cc8c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "inc_model = AutoModel.from_pretrained(\"setfit-mnpet-distilled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0805c4e0-876d-409e-bc9e-79235d919f25",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'onnxrt_integerops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [118], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quantizer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minc_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m quantizer\u001b[38;5;241m.\u001b[39meval_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(eval_func)\n",
      "File \u001b[0;32m~/miniconda3/envs/hf/lib/python3.9/site-packages/neural_compressor/experimental/common/model.py:52\u001b[0m, in \u001b[0;36mModel.__new__\u001b[0;34m(cls, root, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     51\u001b[0m         backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 52\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMODELS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m]\u001b[49m(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     model \u001b[38;5;241m=\u001b[39m MODELS[framework](root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'onnxrt_integerops'"
     ]
    }
   ],
   "source": [
    "quantizer.model = common.Model(inc_model)\n",
    "quantizer.eval_func = functools.partial(eval_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7ca1098-220e-42d3-861d-73a0ba6aedff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 11:04:43 [INFO] Get FP32 model baseline.\n",
      "2022-12-13 11:04:52.711928978 [E:onnxruntime:, sequential_executor.cc:369 Execute] Non-zero status code returned while running FusedMatMul node. Name:'MatMul_86_FusedMatMulAndScale' Status Message: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:342 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool) Failed to allocate memory for requested buffer of size 27990739200\n",
      "\n",
      "2022-12-13 11:04:52 [ERROR] Unexpected exception RuntimeException(\"[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running FusedMatMul node. Name:'MatMul_86_FusedMatMulAndScale' Status Message: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:342 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool) Failed to allocate memory for requested buffer of size 27990739200\\n\") happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/neural_compressor/experimental/quantization.py\", line 161, in execute\n",
      "    self.strategy.traverse()\n",
      "  File \"/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py\", line 222, in traverse\n",
      "    self.baseline = self._evaluate(self.model)\n",
      "  File \"/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/neural_compressor/strategy/strategy.py\", line 703, in _evaluate\n",
      "    val = self.objectives.evaluate(\n",
      "  File \"/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/neural_compressor/objective.py\", line 266, in evaluate\n",
      "    acc = eval_func(model)\n",
      "  File \"/tmp/ipykernel_7619/2987796351.py\", line 16, in eval_func\n",
      "    preds = session.run(None, dict(inputs))[0]\n",
      "  File \"/home/lewis_huggingface_co/miniconda3/envs/hf/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\", line 200, in run\n",
      "    return self._sess.run(output_names, input_feed, run_options)\n",
      "onnxruntime.capi.onnxruntime_pybind11_state.RuntimeException: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Non-zero status code returned while running FusedMatMul node. Name:'MatMul_86_FusedMatMulAndScale' Status Message: /onnxruntime_src/onnxruntime/core/framework/bfc_arena.cc:342 void* onnxruntime::BFCArena::AllocateRawInternal(size_t, bool) Failed to allocate memory for requested buffer of size 27990739200\n",
      "\n",
      "2022-12-13 11:04:52 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n"
     ]
    }
   ],
   "source": [
    "q_model = quantizer()\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abd6ac03-afb5-4b64-ae2f-e99f7b89002a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m(onnx_int8_inc_dynamic_model_path)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "q_model.save(onnx_int8_inc_dynamic_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6806f5d-7350-45fc-a648-925613f25b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
